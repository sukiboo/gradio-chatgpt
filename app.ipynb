{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f2ec94-fbdc-46d9-95eb-2702df8b461d",
   "metadata": {},
   "source": [
    "# An Implementation of ChatGPT via Gradio Interface\n",
    "\n",
    "The code in the first block of this notebook is executed when the `app.py` file is run. This notebook is used for the simplicity of interactive development and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5edaff-cb53-43f7-a60e-1495e3f3361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class GPT:\n",
    "    \"\"\"Instantiate GPT model for a multi-step conversation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Setup model parameters and system prompt.\"\"\"\n",
    "        self.client = OpenAI()\n",
    "        self.messages = []\n",
    "\n",
    "    def chat(self, user_prompt, chat_history, system_prompt, *params):\n",
    "        \"\"\"Generate a response with a given parameters.\"\"\"\n",
    "        # update GPT parameters -- gradio does not allow dict inputs :(\n",
    "        params = {\n",
    "            'model': params[0],\n",
    "            'temperature': params[1],\n",
    "            'top_p': params[2],\n",
    "            'frequency_penalty': params[3],\n",
    "            'presence_penalty': params[4]\n",
    "        }\n",
    "\n",
    "        # update the message buffer\n",
    "        self.messages = [{'role': 'system', 'content': f'{system_prompt}'}]\n",
    "        for prompt, response in chat_history:\n",
    "            self.messages.append({'role': 'user', 'content': f'{prompt}'})\n",
    "            self.messages.append({'role': 'assistant', 'content': f'{response}'})\n",
    "        self.messages.append({'role': 'user', 'content': f'{user_prompt}'})\n",
    "\n",
    "        # generate a response\n",
    "        completion = self.client.chat.completions.create(\n",
    "            messages=self.messages,\n",
    "            **params\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "        self.messages.append({'role': 'assistant', 'content': response})\n",
    "        chat_history.append((user_prompt, response))\n",
    "\n",
    "        # save chat history\n",
    "        chat_name = save_chat(chat_history)\n",
    "\n",
    "        return '', chat_history, gr.DownloadButton('Save Chat', value=chat_name)\n",
    "\n",
    "\n",
    "# TODO: save the model version instead of BOT\n",
    "def save_chat(chat_history):\n",
    "    \"\"\"Write chat history to a file.\"\"\"\n",
    "    chat_name = f'/tmp/chat_{int(time.time())}.txt'\n",
    "    with open(chat_name, 'w', encoding='utf-8') as chat_file:\n",
    "        for user, bot in chat_history:\n",
    "            chat_file.write(f'USER: {user}\\n BOT: {bot}\\n')\n",
    "    return chat_name\n",
    "\n",
    "\n",
    "def download_chat():\n",
    "    \"\"\"Download chat history in a text file.\"\"\"\n",
    "    return gr.DownloadButton(label='Save Chat')\n",
    "\n",
    "\n",
    "def run_chatbot(gpt):\n",
    "    \"\"\"Configure and launch the chatbot interface.\"\"\"\n",
    "    with gr.Blocks(title='ChatGPT') as chatbot:\n",
    "\n",
    "        # chatbot interface\n",
    "        chat_history = gr.Chatbot(\n",
    "            height=500,\n",
    "            layout='bubble',\n",
    "            label='ChatGPT',\n",
    "            bubble_full_width=False,\n",
    "            show_copy_button=True\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            user_prompt = gr.Textbox(\n",
    "                placeholder='Message ChatGPT...',\n",
    "                container=False,\n",
    "                min_width=500,\n",
    "                scale=9\n",
    "            )\n",
    "            submit_button = gr.Button(\n",
    "                value='Submit',\n",
    "                min_width=300\n",
    "            )\n",
    "            save_button = gr.DownloadButton(\n",
    "                value='Save Chat',\n",
    "                min_width=300\n",
    "            )\n",
    "\n",
    "        # parameters accordion\n",
    "        with gr.Accordion(label='GPT Parameters', open=False):\n",
    "            info = gr.Markdown(\n",
    "                'For parameter documentation see [OpenAI Chat API Reference]' \\\n",
    "                + '(https://platform.openai.com/docs/api-reference/chat)'\n",
    "            )\n",
    "\n",
    "            with gr.Row():\n",
    "                system_prompt = gr.Textbox(\n",
    "                    value='You are a helpful assistant.',\n",
    "                    label='system prompt',\n",
    "                    scale=9\n",
    "                )\n",
    "                model_choice = gr.Dropdown(\n",
    "                    value='gpt-4o',\n",
    "                    choices=['gpt-4o', 'gpt-4o-mini'],\n",
    "                    label='model',\n",
    "                    scale=1\n",
    "                )\n",
    "\n",
    "            with gr.Row():\n",
    "                temperature = gr.Slider(\n",
    "                    minimum=0.,\n",
    "                    maximum=2.,\n",
    "                    value=1.,\n",
    "                    step=.1,\n",
    "                    min_width=200,\n",
    "                    label='temperature'\n",
    "                )\n",
    "                top_p = gr.Slider(\n",
    "                    minimum=0.,\n",
    "                    maximum=1.,\n",
    "                    value=1.,\n",
    "                    step=.01,\n",
    "                    min_width=200,\n",
    "                    label='top_p'\n",
    "                )\n",
    "                frequency_penalty = gr.Slider(\n",
    "                    minimum=-2.,\n",
    "                    maximum=2.,\n",
    "                    value=0,\n",
    "                    step=.1,\n",
    "                    min_width=200,\n",
    "                    label='frequency_penalty'\n",
    "                )\n",
    "                presence_penalty = gr.Slider(\n",
    "                    minimum=-2.,\n",
    "                    maximum=2.,\n",
    "                    value=0,\n",
    "                    step=.1,\n",
    "                    min_width=200,\n",
    "                    label='presence_penalty'\n",
    "                )\n",
    "\n",
    "        # submit user prompt and parameters\n",
    "        params = [model_choice, temperature, top_p, frequency_penalty, presence_penalty]\n",
    "        inputs = [user_prompt, chat_history, system_prompt, *params]\n",
    "        outputs = [user_prompt, chat_history, save_button]\n",
    "        submit_button.click(gpt.chat, inputs=inputs, outputs=outputs)\n",
    "        user_prompt.submit(gpt.chat, inputs=inputs, outputs=outputs)\n",
    "\n",
    "        # save chat button\n",
    "        save_button.click(download_chat, inputs=None, outputs=save_button)\n",
    "\n",
    "    # instantiate the chatbot\n",
    "    gr.close_all()\n",
    "    chatbot.queue(default_concurrency_limit=None)\n",
    "    chatbot.launch()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gpt = GPT()\n",
    "    run_chatbot(gpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c9f25-5d97-4b41-83ee-7032f83d5162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
