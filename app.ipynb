{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f2ec94-fbdc-46d9-95eb-2702df8b461d",
   "metadata": {},
   "source": [
    "# An Implementation of ChatGPT via Gradio Interface\n",
    "\n",
    "This notebook contains the same code as `app.py` and can be used for the interactive development and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5edaff-cb53-43f7-a60e-1495e3f3361b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class GPT:\n",
    "    \"\"\"Instantiate GPT model for a multi-step conversation.\"\"\"\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        \"\"\"Setup model parameters and system prompt.\"\"\"\n",
    "        self.client = OpenAI()\n",
    "        self.params = {'model': 'gpt-3.5-turbo', **params}\n",
    "        self.messages = []\n",
    "\n",
    "    def chat(self, user_prompt, chat_history, system_prompt, *params):\n",
    "        \"\"\"Generate a response with a given parameters.\"\"\"\n",
    "\n",
    "        # update GPT parameters\n",
    "        temperature, top_p, frequency_penalty, presence_penalty = params\n",
    "        self.params['temperature'] = temperature\n",
    "        self.params['top_p'] = top_p\n",
    "        self.params['frequency_penalty'] = frequency_penalty\n",
    "        self.params['presence_penalty'] = presence_penalty\n",
    "\n",
    "        # update the message buffer\n",
    "        self.messages = [{'role': 'system', 'content': f'{system_prompt}'}]\n",
    "        for prompt, response in chat_history:\n",
    "            self.messages.append({'role': 'user', 'content': f'{prompt}'})\n",
    "            self.messages.append({'role': 'assistant', 'content': f'{response}'})\n",
    "        self.messages.append({'role': 'user', 'content': f'{user_prompt}'})\n",
    "\n",
    "        # generate a response\n",
    "        completion = self.client.chat.completions.create(messages=self.messages, **self.params)\n",
    "        response = completion.choices[0].message.content\n",
    "        self.messages.append({'role': 'assistant', 'content': response})\n",
    "        chat_history.append((user_prompt, response))\n",
    "\n",
    "        return '', chat_history\n",
    "\n",
    "\n",
    "def run_chatbot(gpt):\n",
    "    \"\"\"Configure and launch the chatbot interface.\"\"\"\n",
    "    with gr.Blocks(title='ChatGPT') as chatbot:\n",
    "\n",
    "        # chatbot interface\n",
    "        chat_history = gr.Chatbot(height=500, layout='bubble', label='ChatGPT')\n",
    "        with gr.Row():\n",
    "            user_prompt = gr.Textbox(placeholder='Message ChatGPT...', container=False, scale=9)\n",
    "            submit_button = gr.Button('Submit')\n",
    "\n",
    "        # parameters accordion\n",
    "        with gr.Accordion(label='GPT Parameters', open=False):\n",
    "            info = gr.Markdown('For parameter documentation see [OpenAI Chat API Reference]' \\\n",
    "                               + '(https://platform.openai.com/docs/api-reference/chat)')\n",
    "            system_prompt = gr.Textbox('You are a helpful assistant.', label='system prompt')\n",
    "            with gr.Row():\n",
    "                temperature = gr.Slider(0., 2., value=1., step=.1, min_width=200, label='temperature')\n",
    "                top_p = gr.Slider(0., 1., value=1., step=.01, min_width=200, label='top_p')\n",
    "                frequency_penalty = gr.Slider(-2., 2., value=0, step=.1, min_width=200, label='frequency_penalty')\n",
    "                presence_penalty = gr.Slider(-2., 2., value=0, step=.1, min_width=200, label='presence_penalty')\n",
    "\n",
    "        # submit user prompt\n",
    "        submit_button.click(gpt.chat,\n",
    "                            inputs=[user_prompt, chat_history, system_prompt,\n",
    "                                    temperature, top_p, frequency_penalty, presence_penalty],\n",
    "                            outputs=[user_prompt, chat_history])\n",
    "        user_prompt.submit(gpt.chat,\n",
    "                           inputs=[user_prompt, chat_history, system_prompt,\n",
    "                                   temperature, top_p, frequency_penalty, presence_penalty],\n",
    "                           outputs=[user_prompt, chat_history])\n",
    "\n",
    "    # instantiate the chatbot\n",
    "    gr.close_all()\n",
    "    chatbot.queue(default_concurrency_limit=None)\n",
    "    chatbot.launch()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gpt = GPT()\n",
    "    run_chatbot(gpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c9f25-5d97-4b41-83ee-7032f83d5162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
