{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f2ec94-fbdc-46d9-95eb-2702df8b461d",
   "metadata": {},
   "source": [
    "# An Implementation of ChatGPT via Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6d5edaff-cb53-43f7-a60e-1495e3f3361b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7940\n",
      "Running on local URL:  http://127.0.0.1:7951\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7951/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class GPT:\n",
    "    \"\"\"Instantiate GPT model for a multi-step conversation.\"\"\"\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        \"\"\"Setup model parameters and system prompt.\"\"\"\n",
    "        self.client = OpenAI()\n",
    "        self.params = {'model': 'gpt-3.5-turbo', **params}\n",
    "        self.messages = []\n",
    "\n",
    "    def chat(self, user_prompt, history=[], *params):\n",
    "        \"\"\"Update model parameters and generate a response.\"\"\"\n",
    "        _, system_prompt, temperature, top_p, frequency_penalty, presence_penalty = params\n",
    "\n",
    "        # update the parameters\n",
    "        self.params['temperature'] = temperature\n",
    "        self.params['top_p'] = top_p\n",
    "        self.params['frequency_penalty'] = frequency_penalty\n",
    "        self.params['presence_penalty'] = presence_penalty\n",
    "\n",
    "        # update the message buffer\n",
    "        self.messages = [{'role': 'system', 'content': f'{system_prompt}'}]\n",
    "        for prompt, response in history:\n",
    "            self.messages.append({'role': 'user', 'content': f'{prompt}'})\n",
    "            self.messages.append({'role': 'assistant', 'content': f'{response}'})\n",
    "        self.messages.append({'role': 'user', 'content': f'{user_prompt}'})\n",
    "\n",
    "        # generate a response\n",
    "        completion = self.client.chat.completions.create(messages=self.messages, **self.params)\n",
    "        response = completion.choices[0].message.content\n",
    "        self.messages.append({'role': 'assistant', 'content': response})\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "def run_chatbot(gpt):\n",
    "    \"\"\"Configure and launch the chatbot interface.\"\"\"\n",
    "    gr.close_all()\n",
    "    with gr.Blocks() as chatbot:\n",
    "\n",
    "        # parameters accordion\n",
    "        info = gr.Markdown('For additional parameters see [OpenAI Chat API Reference]' \\\n",
    "                           + '(https://platform.openai.com/docs/api-reference/chat)',\n",
    "                           render=False)\n",
    "        system_prompt = gr.Textbox('You are a helpful assistant.', label='system prompt', render=False)\n",
    "        temperature = gr.Slider(0., 2., value=1., step=.1, label='temperature', render=False)\n",
    "        top_p = gr.Slider(0., 1., value=1., step=.01, label='top_p', render=False)\n",
    "        frequency_penalty = gr.Slider(-2., 2., value=0, step=.1, label='frequency_penalty', render=False)\n",
    "        presence_penalty = gr.Slider(-2., 2., value=0, step=.1, label='presence_penalty', render=False)\n",
    "\n",
    "        # chatbot interface\n",
    "        gr.ChatInterface(\n",
    "            fn=gpt.chat,\n",
    "            title='ChatGPT',\n",
    "            description='A simple implementation of ChatGPT',\n",
    "            chatbot=gr.Chatbot(height=600, layout='bubble', label='ChatGPT', render=False),\n",
    "            textbox=gr.Textbox(placeholder='Message ChatGPT...', scale=9, render=False),\n",
    "            additional_inputs_accordion=gr.Accordion(label='Parameters', open=False, render=False),\n",
    "            additional_inputs=[info, system_prompt,\n",
    "                               temperature, top_p,\n",
    "                               frequency_penalty, presence_penalty],\n",
    "            retry_btn=None,\n",
    "            undo_btn=None,\n",
    "            clear_btn=None,\n",
    "            concurrency_limit=None,\n",
    "            theme=None,\n",
    "        )\n",
    "    chatbot.launch()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gpt = GPT()\n",
    "    run_chatbot(gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9b016-37e0-4547-a9ef-c7facbfc43b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c55bcb-6c99-4341-bfad-1515333ef6db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bed1e7-5645-4ea4-954c-57b308447797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74951d09-9611-4617-b895-6b203dd18d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ed8d5-ac39-4c99-9260-a76d774eff5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c1bbd-df97-46a6-af00-f7a4223bdaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d0b6b-0057-4195-8dd7-2d0cabab7b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f7eacf-6bf4-4d0e-b7b5-6ef354ef59a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9afa1b-acfa-435d-b440-4c2a993f12c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61606f6-f20b-4a36-8f9e-4c475fdc2796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b990d33-8176-48c5-8cb1-fb95584ddf63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f70f9-b0b4-434c-99a3-0bc713ba23f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f92239-c920-4933-80bd-7edf6d2623ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a9cf6-8581-4e2e-be9b-70432ece3611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559fab2-3861-4314-9181-a8d127a662e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19753c-5594-4504-919d-e7a6c1ef54f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
