{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f2ec94-fbdc-46d9-95eb-2702df8b461d",
   "metadata": {},
   "source": [
    "# An Implementation of ChatGPT via Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5edaff-cb53-43f7-a60e-1495e3f3361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "class GPT:\n",
    "    \"\"\"Instantiate GPT model for a multi-step conversation.\"\"\"\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        \"\"\"Setup model parameters and system prompt.\"\"\"\n",
    "        self.params = {'model': 'gpt-3.5-turbo', **params}\n",
    "        self.messages = [{'role': 'system', 'content': 'You are a helpful assistant.'}]\n",
    "\n",
    "    def chat(self, user_prompt, history=None, *params):\n",
    "        \"\"\"Update model parameters and generate a response.\"\"\"\n",
    "        # parse and update the parameters\n",
    "        _, system_prompt, temperature, top_p, frequency_penalty, presence_penalty = params\n",
    "        self.params['temperature'] = temperature\n",
    "        self.params['top_p'] = top_p\n",
    "        self.params['frequency_penalty'] = frequency_penalty\n",
    "        self.params['presence_penalty'] = presence_penalty\n",
    "\n",
    "        # update the message buffer and get a response\n",
    "        self.messages[0]['content'] = f'{system_prompt}'\n",
    "        self.messages.append({'role': 'user', 'content': f'{user_prompt}'})\n",
    "        completion = client.chat.completions.create(messages=self.messages, **self.params)\n",
    "        response = completion.choices[0].message.content\n",
    "        self.messages.append({'role': 'assistant', 'content': response})\n",
    "\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287fc55c-e89c-436d-a34c-fa4da598c9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.close_all()\n",
    "gpt = GPT()\n",
    "\n",
    "with gr.Blocks() as chatbot:\n",
    "\n",
    "    # parameters accordion\n",
    "    info = gr.Markdown('For additional parameters see [OpenAI Chat API Reference](https://platform.openai.com/docs/api-reference/chat)',\n",
    "                       render=False)\n",
    "    system_prompt = gr.Textbox('You are a helpful assistant.', label='system prompt', render=False)\n",
    "    temperature = gr.Slider(0., 2., value=1., step=.1, label='temperature', render=False)\n",
    "    top_p = gr.Slider(0., 1., value=1., step=.01, label='top_p', render=False)\n",
    "    frequency_penalty = gr.Slider(-2., 2., value=0, step=.1, label='frequency_penalty', render=False)\n",
    "    presence_penalty = gr.Slider(-2., 2., value=0, step=.1, label='presence_penalty', render=False)\n",
    "\n",
    "    # chatbot interface\n",
    "    gr.ChatInterface(\n",
    "        fn=gpt.chat,\n",
    "        title='ChatGPT',\n",
    "        description='A simple implementation of ChatGPT',\n",
    "        chatbot=gr.Chatbot(height=600, layout='bubble', render=False),\n",
    "        textbox=gr.Textbox(placeholder='Message ChatGPT...', scale=9, render=False),\n",
    "        additional_inputs_accordion=gr.Accordion(label='Parameters', open=False, render=False),\n",
    "        additional_inputs=[info, system_prompt, temperature, top_p, frequency_penalty, presence_penalty],\n",
    "        retry_btn=None,\n",
    "        undo_btn=None,\n",
    "        clear_btn=None,\n",
    "        concurrency_limit=None,\n",
    "        theme=None,\n",
    "    )\n",
    "\n",
    "chatbot.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19753c-5594-4504-919d-e7a6c1ef54f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
